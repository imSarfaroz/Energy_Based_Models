{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q4bg_LgvksvZ"
      },
      "outputs": [],
      "source": [
        "# Importing neccassary torch libraries\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "\n",
        "# numpy for numerical operations and matplotlib for plotting the image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# libraries for handling datasets, image transformations, and visualizing data.\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BM(nn.Module): # Here i am defining BM class from nn.Module, which the base class for all neural network modules in PyTorch\n",
        "    def __init__(self, n_visible, n_hidden):\n",
        "        super(BM, self).__init__()\n",
        "        self.n_visible = n_visible\n",
        "        self.n_hidden = n_hidden\n",
        "\n",
        "       # Initialize weights and biases\n",
        "        self.W = nn.Parameter(torch.randn(n_visible, n_hidden) * 0.1)  # inter-layer weights\n",
        "        self.Wvv = nn.Parameter(torch.randn(n_visible, n_visible) * 0.1)  # Visible-visible weights\n",
        "        self.Whh = nn.Parameter(torch.randn(n_hidden, n_hidden) * 0.1)  # Hidden-hidden weights\n",
        "        self.b_visible = nn.Parameter(torch.zeros(n_visible))  # visible biases\n",
        "        self.b_hidden = nn.Parameter(torch.zeros(n_hidden))  # hidden biases\n",
        "\n",
        "    def sample_hidden(self, visible):\n",
        "        # Computing the activations of the hidden units given the visible units.\n",
        "\n",
        "        activation = torch.matmul(visible, self.W) + self.b_hidden\n",
        "        p_hidden = torch.sigmoid(activation)\n",
        "        sampled_hidden = torch.bernoulli(p_hidden)\n",
        "\n",
        "        return sampled_hidden\n",
        "\n",
        "    def sample_visible(self, hidden):\n",
        "        # Computing the activations of the visible units given the hidden units.\n",
        "\n",
        "        activation = torch.matmul(hidden, self.W.t()) + self.b_visible\n",
        "        p_visible = torch.sigmoid(activation)\n",
        "        sampled_visible = torch.bernoulli(p_visible)\n",
        "        return sampled_visible\n",
        "\n",
        "    def energy(self, visible, hidden):\n",
        "        # Computing the energy of the current configuration of visible and hidden units.\n",
        "\n",
        "        batch_size = visible.shape[0]\n",
        "        # Computing the interaction terms\n",
        "        energy = -torch.sum(torch.matmul(visible, self.W) * hidden, dim=1)\n",
        "        energy -= 0.5 * torch.sum(torch.matmul(visible, self.Wvv) * visible, dim=1)\n",
        "        energy -= 0.5 * torch.sum(torch.matmul(hidden, self.Whh) * hidden, dim=1)\n",
        "\n",
        "        # Computing the bias terms\n",
        "        energy -= torch.sum(visible * self.b_visible, dim=1)\n",
        "        energy -= torch.sum(hidden * self.b_hidden, dim=1)\n",
        "        return energy.mean()  # Returning the average energy over the batch\n",
        "\n",
        "    def forward(self, visible):\n",
        "        # Performing a forward pass to compute the activations of the hidden units.\n",
        "        hidden = self.sample_hidden(visible)\n",
        "        visible_gibbs = self.sample_visible(hidden)\n",
        "        return visible, visible_gibbs"
      ],
      "metadata": {
        "id": "LFfTgghuMdrx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mse(original, reconstructed):\n",
        "    return ((original - reconstructed) ** 2).mean()\n",
        "\n",
        "\n",
        "def train(bm, train_loader, optimizer, epochs, device):\n",
        "    # Training BM on MNIST datset\n",
        "\n",
        "    bm.to(device)  # Move the model to the device (CPU/GPU)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_mse = 0\n",
        "        for batch, (data, _) in enumerate(train_loader):\n",
        "            data = data.view(-1, 784).to(device)\n",
        "            data = torch.bernoulli(data)\n",
        "\n",
        "            # Performing CD training\n",
        "            hidden = bm.sample_hidden(data)\n",
        "            visible_recon = bm.sample_visible(hidden)\n",
        "\n",
        "            # Calculating reconstruction error\n",
        "            mse = calculate_mse(data, visible_recon)\n",
        "            total_mse += mse.item()\n",
        "\n",
        "            hidden_recon = bm.sample_hidden(visible_recon)\n",
        "            positive_grad = bm.energy(data, hidden)\n",
        "            negative_grad = bm.energy(visible_recon, hidden_recon)\n",
        "\n",
        "            # Computing the gradients and updating the model parameters\n",
        "            loss = positive_grad - negative_grad\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Average MSE over all batches\n",
        "        average_mse = total_mse / len(train_loader)\n",
        "        print(f\"Epoch: {epoch+1}/{epochs}, Avg MSE: {average_mse:.2f}\")"
      ],
      "metadata": {
        "id": "LI5o1hRkMmNq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Addinitional function to save and show image while executing\n",
        "def show_and_save(img, file_name):\n",
        "    pic = np.transpose(img.cpu().numpy(), (1, 2, 0))\n",
        "    f = \"./%s.png\" % file_name\n",
        "    plt.imshow(pic, cmap='gray')\n",
        "    plt.imsave(f, pic)"
      ],
      "metadata": {
        "id": "Jp43QDs8MqGG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPER-PARAMETERS (experimented with various hyperparameters below)\n",
        "batch_size = 40\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "num_hidden = 500\n",
        "num_visible = 784"
      ],
      "metadata": {
        "id": "8pG2mvbeM0js"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code initializes a DataLoader for the MNIST dataset, downloading it if necessary,\n",
        "# onverting images to tensors, and organizing them into batches of a specified size for training. Saving results in ./ouput file\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./output', train=True, download=True, transform=transforms.Compose([ transforms.ToTensor() ])),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "uDrDIXFIctlZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BM(num_visible, num_hidden)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "IkWG0D8-NBB9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Boltzmann Machine (using CUDA-GPU in google colab if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train(model, train_loader, optimizer, num_epochs, device=device)"
      ],
      "metadata": {
        "id": "oBinRcoaNEMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "images = next(iter(train_loader))[0]\n",
        "images = images.float()\n",
        "images = images.view(-1, 784)  # Reshape the input images to (batch_size, 784)\n",
        "images = images.to(device)\n",
        "v, v_gibbs = model.forward(images)"
      ],
      "metadata": {
        "id": "b_Xvu9bzLBhL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and showing original image\n",
        "show_and_save(make_grid(v.view(batch_size, 1, 28, 28).data), 'output/original_images')"
      ],
      "metadata": {
        "id": "Wm9S2TIvAlYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and showing generated image by RBM\n",
        "show_and_save(make_grid(v_gibbs.view(batch_size, 1, 28, 28).data), 'output/generated_image')"
      ],
      "metadata": {
        "id": "tGaxjgBWG0mu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}